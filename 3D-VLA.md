
## 3D-VLA 的 Action Head 设计详解

在论文《3D-VLA: A 3D Vision-Language-Action Generative World Model》中，模型采用了基于 **离散动作 token 的自回归生成机制**，通过语言模型直接输出动作令牌，用于机器人控制。这一机制构成了 3D-VLA 的 **Action Head**，实现了与语言和图像模态统一的 token 表达方式。

---

### 一、核心思想

3D-VLA 将每个动作表示为一组 **离散 token**，这些 token 是由语言模型自回归预测生成的，表示机器人需要执行的控制命令。整个动作序列嵌入在语言模型生成路径中，模型以统一的 token 序列形式输出：

| 类型       | 表达形式                             | 说明                       |
|------------|--------------------------------------|----------------------------|
| 平移动作 ΔT | `<aloc0-255>`                        | 表示笛卡尔/极坐标位置编码 |
| 旋转动作 ΔR | `<arot0-255>`                        | 表示欧拉角方向             |
| 抓取动作 G  | `<gripper0>` 或 `<gripper1>`         | 表示夹爪开闭状态           |

动作 token 使用特定语法结构表示并由 `<ACT SEP>` 分隔，嵌入在输出序列中作为机器人执行的行为指令。

---

### 二、Action Token 设计机制

3D-VLA 的动作表示设计方式如下：

1. **连续动作离散化**：
   - 将机器人每个控制维度（位置、姿态、gripper）分别离散为 256 个 bin；
   - 每个 bin 映射为一个特定的 token，如 `<aloc128>` 表示位置第128个bin。

2. **动作 token 格式示例**：

```
<aloc128> <aloc92> <aloc45> <arot103> <arot86> <arot200> <gripper1> <ACT SEP>
```

表示一个完整的机器人控制动作，包括位置、姿态与抓取。

3. **训练目标**：
   - 与语言生成相同，采用 **auto-regressive next-token prediction**；
   - 每一步动作的 token 被视为语言 token 一样处理，优化目标为标准交叉熵。

---

### 三、动作头流程概述

#### 编码：
- 将机器人动作采样转换为一组 token（7~8个）；
- 每个 token 代表某个离散动作维度，如 `<arot124>` 表示旋转角度bin；
- 输入模型时作为目标token序列训练。

#### 解码：
- 模型自回归输出 token 序列；
- 每个动作由一串连续 token 表示，直到 `<ACT SEP>` 为止；
- 后处理模块将 token 反映射为真实动作向量执行控制。

---

### 四、与其他模型对比

| 模型       | Action Head类型         | 动作维度 | 每步Token数 | 是否3D建模 | 是否自适应离散 |
|------------|--------------------------|-----------|--------------|--------------|------------------|
| RT-1       | 固定Bin + token输出      | 11        | 7             | 否           | 否               |
| RT-2       | 固定Bin + token输出      | 8         | 7             | 否           | 否               |
| OpenVLA    | 固定Bin + token输出      | 7         | 7             | 否           | 否               |
| SpatialVLA | Adaptive Action Grid      | 7         | **3**         | 是           | 是               |
| **3D-VLA** | **动作token序列 + LLM输出** | 7         | **7C8**       | 是（3D token）| 是（token级建模）|

---

### 五、设计优势总结

-  **自然融合语言与动作**：动作直接嵌入语言生成序列，统一模态；
-  **支持3D语义定位**：动作 token 与视觉-语言空间共同建模，有助于空间推理；
-  **泛化能力强**：可生成任意长度的动作序列，适用于复杂场景任务；
-  **扩展性高**：token级控制便于嵌入额外控制信号，如 `<stop>`、`<reset>` 等。
