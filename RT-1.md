
## RT-1 的 Action Head 设计详解

RT-1 模型是 Google Robotics 提出的早期 Vision-Language-Action 架构之一，其 **Action Head** 并非传统回归式控制器，而是一个**多维离散化动作分类器**，在 Transformer 解码器上直接输出离散的控制动作 token。这一机制为后续 RT-2、OpenVLA 等模型的 token-based 控制方式奠定了基础。

---

### 一、核心思想

RT-1 模型将机器人控制命令的连续动作向量进行 **维度独立离散化**，将每个控制维度分成 256 个区间（bin），并将每个维度预测为一个离散分类任务，构成多头分类器（multi-head classifier）。

| 控制类型       | 维度数 | 说明                               |
|----------------|--------|------------------------------------|
| 手臂控制 Arm    | 7      | x, y, z + 欧拉角 (roll, pitch, yaw) + gripper |
| 移动底盘 Base   | 3      | x, y 平移 + yaw 旋转               |
| 模式切换 Mode   | 1      | 表示是否执行抓取/放置或控制底盘    |
| **总计**        | **11** |                                   |

---

### 二、Action Head 设计机制

#### 1. **动作离散化**：

- 所有 11 个维度被分别离散为 256 个 bin；
- 每个维度的离散表示由其真实值的位置对应的 bin index 表示；
- 动作向量最终表示为长度为 11 的整数序列，每个值 ∈ [0, 255]。

#### 2. **模型输出格式**：

- 动作头由 Transformer Decoder 输出一个长度为 11 的序列；
- 每个维度对应一个 256-way 的 softmax 分类器；
- 训练损失为 **11 个分类的交叉熵和**。

---

### 三、动作预测流程

#### 编码（训练时）：
- 将连续控制量（如 gripper=0.7） → 映射为 bin（如 bin=179）；
- 每个样本被转换为 11 个动作 token，作为 Transformer 的预测目标；
- 与语言模型结构类似，但目标是离散 token 而非自然语言。

#### 解码（推理时）：
- 模型输出 11 个 logits → 取每个维度 top-1 作为 bin；
- 每个 bin 映射回原始动作空间（通常为区间中心）；
- 将解码后的连续动作发送至机器人控制器执行。

---

### 四、与其他模型对比

| 模型       | 动作头方式                | Token数/step | 是否自回归 | 是否语言共享 | 是否3D感知 |
|------------|---------------------------|--------------|--------------|----------------|--------------|
| **RT-1**   | **11分类器（256 bins）**   | 11           | 否（并行）   | 否             | 否           |
| RT-2       | Token + LLM（7维）        | 7            | ?            | ?             | 否           |
| OpenVLA    | Token + Quantile DeTokenizer | 7         | ?            | ?             | 否           |
| 3D-VLA     | 3D Token序列               | 7C8          | ?            | ?             | ?           |
| SpatialVLA | Adaptive Action Grid Token | 3            | ?            | ?             | ?           |

---

### 五、设计优势总结

- **高效训练**：不使用自回归结构，所有动作维度并行预测；
- **工程实现简单**：将每个动作看作独立分类问题，适配现有 Transformer 架构；
- **规模可扩展性强**：适用于 RT-1 中 130k 个任务、70k 小时的大规模数据；
- **支持多机器人融合训练**：多个 robot embodiment 可共享同一动作编码器框架；
- **为 token-based 动作建模打基础**：启发后续 RT-2、OpenVLA 采用统一 token 序列生成动作。

