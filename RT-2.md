
## RT-2 的 Action Head 设计详解

RT-2 是 Google DeepMind 提出的跨模态机器人控制模型，它将机器人动作表示为**离散 token 序列**，统一嵌入语言模型输出序列中进行生成。该方法继承 RT-1 的离散思想，同时融合自然语言 token 机制，是一种**语言化（tokenized）控制策略**，构成其 Action Head 的核心。

---

### 一、核心思想

RT-2 将每一个机器人的连续动作表示成 **离散整数 token**，并用标准语言模型方式逐 token 输出这些动作。这些动作维度包括：

| 控制维度       | 说明                                     |
|----------------|------------------------------------------|
| ΔPosition (3D) | 末端执行器的位置变化 Δx, Δy, Δz           |
| ΔRotation (3D) | 姿态变化（roll, pitch, yaw）              |
| Gripper        | 抓取器张开程度（scalar）                 |
| Terminate      | 表示当前动作序列是否应终止（0或1）        |
| **总计**        | **共 8 维控制变量**                       |

---

### 二、Action Token 表达与建模方式

#### 1. **动作离散化与 token 映射**

- 所有 8 个连续维度均被**均匀离散为 256 个 bin**（整数 ∈ [0,255]）；
- 每个动作向量可表示为长度为 8 的整数序列；
- 动作序列被格式化为一个字符串，如：

  ```
  “1 128 91 241 5 101 127 64”
  ```

- 动作 token 和语言 token **共享同一输出空间**，可以直接输入语言模型。

#### 2. **Token 映射策略**

| 模型变体   | Token 处理方式说明                                                 |
|------------|--------------------------------------------------------------------|
| PaLI-X     | 支持整数映射到唯一 token（0-1000），直接使用 token                |
| PaLM-E     | 不支持整数直接映射，用**最少使用的 256 个 token**覆盖为动作 token |
| → 总结     | 两者皆采用“符号微调（symbol tuning）”的策略实现动作 token 定义     |

---

### 三、训练与推理流程

#### 编码阶段（训练）：
- 使用标准文本 QA 格式构造训练输入：
  ```
  Q: what action should the robot take to [instruction]?
  A: 1 128 91 241 5 101 127 64
  ```
- 输出 token 与语言模型序列统一处理，使用**next-token prediction**训练。

#### 解码阶段（推理）：
- 模型自回归输出动作 token；
- 将 token 映射回离散 bin → 还原为连续控制信号；
- 由 robot controller 执行动作；
- 使用动作类型 prompt 限制 decoder 输出 **仅采样动作 token**，提高执行合法性。

---

### 四、与其他模型对比

| 模型       | Action Head方式            | Token数/step | 是否自回归 | 是否语言共享 | 是否空间建模 |
|------------|-----------------------------|----------------|--------------|----------------|----------------|
| RT-1       | 多分类器（每维1个256分类）  | 11             | 否（并行）   | 否             | 否             |
| **RT-2**   | **离散动作 token + 自回归生成** | **8**          | 是            | 是             | 否             |
| OpenVLA    | 离散 token（量化 + de-tokenizer） | 7           | 是           | 是           | 否             |
| 3D-VLA     | 动作 token 嵌入序列         | 7C8            | 是          | 是           | 是             |
| SpatialVLA | 自适应空间动作网格 + token   | 3              | 是            | 是            | 是             |

---

### 五、设计优势总结

- **统一语言与动作建模**：动作可直接作为语言 token 处理，架构简单；
- **良好的迁移能力**：可迁移大规模语言+图像知识用于机器人控制；
- **符号微调高效**：不增加新 token，复用原有 tokenizer；
- **控制稳定性高**：推理时限制 vocab 范围，仅输出动作 token，降低出错率；
- **扩展性强**：支持任意指令/图像输入、生成高维动作控制。
