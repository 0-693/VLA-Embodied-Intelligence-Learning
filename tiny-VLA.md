

## TinyVLA 的 Action Head 设计详解

TinyVLA 是一类轻量级的 Vision-Language-Action（VLA）模型，其 **Action Head** 不再采用传统的 token 自回归生成方式，而是引入了 **Diffusion Policy Head（扩散策略头）** 来输出机器人控制动作。这一设计在保留语义理解与泛化能力的同时，大幅提升了推理效率与数据利用率，是一种融合扩散模型与预训练多模态语言模型的新型动作生成机制。

---

### 一、核心思想

与 RT-2、OpenVLA 使用离散动作 token 不同，TinyVLA 直接用 **连续控制量作为输出目标**，通过扩散模型（DDPM）方式生成动作序列。

| 动作维度      | 表达内容                 |
|---------------|--------------------------|
| Position (3D) | x, y, z                  |
| Rotation (3D) | roll, pitch, yaw         |
| Gripper (1D)  | 抓取器开合状态（标量）   |
| **总计**       | **7维连续控制向量**      |

---

### 二、Action Head 结构与扩散机制

#### 1. **动作输出不再 token 化**
- 不采用 RT-2 那种“动作离散 → token → 自回归生成”方式；
- 改为直接在连续空间中建模，用扩散模型生成动作向量。

#### 2. **扩散策略结构（Diffusion Policy Head）**

- 模型结构如图 2 所示（论文右侧部分）；
- 包含两层简单的 **Linear 投影 + LayerNorm**，将多模态 embedding 映射为扩散控制条件；
- 动作预测过程如下：

  **训练阶段（Forward Process）：**
  - 从真实动作 a? 添加 K 次高斯噪声：\( a_K = a_0 + \mathcal{N}(0, \sigma_K^2) \)
  - 模型学习从 a_K 恢复出 a? 的去噪向量

  **推理阶段（Reverse Process）：**
  - 从随机高斯噪声 a_N 开始，迭代去噪直到得到 a?

---

### 三、训练与推理流程

#### 编码阶段（训练）：
- 模型输入：图像观察 + 文本指令；
- 目标输出：连续控制动作；
- 损失函数：预测噪声误差（标准扩散策略训练）；
  \[
  \mathcal{L} = \mathbb{E}_{\epsilon \sim \mathcal{N}} \left[ \|\epsilon - \hat{\epsilon}_\theta(a_t + \epsilon \mid o_t, l_t)\|^2 \right]
  \]

#### 解码阶段（推理）：
- 从随机噪声 a_N 开始，扩散策略逐步生成动作向量；
- 输出为一个完整的 7D 连续控制向量；
- 相比 token-based 方法只需一次推理，无需逐 token 生成。

---

### 四、与其他模型对比（动作头）

| 模型         | 动作头类型            | Token数/step | 是否自回归 | 是否语言共享 | 是否支持高效推理 |
|--------------|-------------------------|---------------|--------------|----------------|------------------|
| RT-1         | 多维分类器              | 11            | 否           | 否             | 中               |
| RT-2         | 自回归 token + de-tokenizer | 8         | 是           | 是             | 否（慢）         |
| OpenVLA      | token输出 + de-tokenizer   | 7            | 是           | 是             | 否（慢）         |
| 3D-VLA       | token序列生成             | 7C8          | 是           | 是             | 否（中等）       |
| **TinyVLA**  | **Diffusion Policy Head** | **1次输出7D** | 否           | 是（条件控制） | 是（最快）    |

---

### 五、设计优势总结

- **极高推理效率**：非自回归，仅需一次前向推理即可输出完整动作；
- **天然支持连续控制空间**：避免 token 化对高精度控制的限制；
- **参数高效（LoRA）**：训练仅需 5% 参数更新，适合边缘部署；
- **跨模态泛化强**：语言视觉知识通过预训练多模态模型引入；
- **无需大规模机器人预训练**：不依赖 OpenX 等大数据集也能训练成功；
- **强现实表现**：在真实任务中超越 OpenVLA，推理速度快 20 倍。

